# -*- coding: utf-8 -*-
"""kidney disease prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MZyHinxEaB-FFMmypEnlrNxtznvtGJZF
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""# **Loading the Kidney Disease Dataset**
This section of the code prepares the environment for data analysis by importing necessary libraries and loading the kidney disease dataset from Google Drive. It establishes a connection to Google Drive, navigates to the file location, and reads the data into a pandas DataFrame (df) for subsequent processing and exploration
"""

from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Navigate to the folder containing your CSV file
folder_path = '/content/drive/MyDrive/'  # Corrected: Path to the folder containing the CSV
os.chdir(folder_path)

# Read the CSV file
file_name = 'kidney_disease.csv'  # Replace with the actual file name
df = pd.read_csv(file_name)

"""# **Previewing the Data**
This line of code uses the .head() method to display the first 20 rows of the DataFrame df. This allows for a quick visual inspection of the data, helping us to understand the structure of the dataset, column names, and the types of values stored within the columns.
"""

df.head(20)





"""# **Descriptive Analysis of Numerical Features**
*   *count*: The number of non-missing values in each column.
*   mean: The average value of each column.
*   std: The standard deviation, which measures how spread out the data is.
*   min: The minimum value in each column.
*   25%: The 25th percentile (first quartile), which is the value below which 25% of the data falls.
*   50%: The 50th percentile (median), which is the middle value when the data is sorted.
*   75%: The 75th percentile (third quartile), which is the value below which 75% of the data falls.
*   max: The maximum value in each column.

In essence, df.describe() gives a quick overview of the key statistical properties of the numerical data within our DataFrame.
"""

df.describe()

df.info()

"""# **Creating a Histogram of Patient Ages**"""

import matplotlib.pyplot as plt

plt.hist(df['age'], bins=10)  # Adjust 'age' with the desired column
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Distribution of Age')
plt.show()

"""# **Box Plot Analysis of Kidney Disease Patient Data**"""

df.isnull().sum()
numerical_cols = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']

# Create the box plot for the selected columns
df[numerical_cols].plot(kind='box', subplots=True, layout=(4, 4), figsize=(15, 10), sharex=False, sharey=False)
plt.tight_layout()  # Adjust layout for better spacing
plt.show()

"""# **Visualizing Missing Data with a Heatmap**"""

sns.heatmap(df.isnull())

df.shape

from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()
df['rbc']=lb.fit_transform(df['rbc'])
df['pc']=lb.fit_transform(df['pc'])
df['pcc']=lb.fit_transform(df['pcc'])
df['ba']=lb.fit_transform(df['ba'])
df['htn']=lb.fit_transform(df['htn'])
df['dm']=lb.fit_transform(df['dm'])
df['cad']=lb.fit_transform(df['cad'])
df['appet']=lb.fit_transform(df['appet'])
df['pe']=lb.fit_transform(df['pe'])
df['ane']=lb.fit_transform(df['ane'])
df['classification']=lb.fit_transform(df['classification'])

print(df)

df['age']=df['age'].fillna(df['age'].mean())

df.replace('\t?', float('nan'), inplace=True)  # Replace '\t?' with NaN

# Convert the relevant columns to float
columns_to_convert = [ 'bp',     'sg',   'al' ,  'su',  'rbc',  'pc',  'pcc' , 'ba'  ,'bgr', 'bu', 'sc', 'sod', 'pot' ,'hemo' ,'pcv' , 'wc' , 'rc' ,'htn',  'dm'  ,'cad',  'appet' , 'pe' , 'ane' , 'classification']  # Replace with the actual column names
for column in columns_to_convert:
    df[column] = pd.to_numeric(df[column], errors='coerce')

# Drop rows with missing values
df.dropna(inplace=True)

!pip install fancyimpute
from fancyimpute import KNN

!pip install fancyimpute
from fancyimpute import KNN

df=pd.DataFrame(df,columns=['id',   'age',   'bp',     'sg',   'al' ,  'su',  'rbc',  'pc',  'pcc' , 'ba'  ,'bgr', 'bu', 'sc', 'sod', 'pot' ,'hemo' ,'pcv' , 'wc' , 'rc' ,'htn',  'dm'  ,'cad',  'appet' , 'pe' , 'ane' , 'classification'])

df.head(30)

X = df.drop('classification', axis=1) # Use the column name 'classification' and specify axis=1 for columns
y = df['classification'][0:203]

from sklearn.model_selection import train_test_split

X = df.drop('classification', axis=1)  # Features
y = df['classification']  # Target - use the entire column

# Now, X and y should have the same number of samples.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train,y_train)
y_pred = knn.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix,mean_absolute_error

print(classification_report(y_test,y_pred))

"""# **Confusion Matrix**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming you have y_test and y_pred from your previous code

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))  # Adjust figure size if needed
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Class 0", "Class 1"],  # Replace with your class labels
            yticklabels=["Class 0", "Class 1"])  # Replace with your class labels
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""# **Classification Report**"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()
rf.fit(X_train,y_train)
y_pred1 = rf.predict(X_test)
print(classification_report(y_test,y_pred1))

from sklearn.metrics import roc_curve, auc

from sklearn.metrics import roc_curve, auc

# Assuming y_test contains values 0 and 2
# Replace 2 with 1 in y_test
y_test_binary = y_test.replace(2, 1)

if len(set(y_test_binary)) == 2:  # Check if binary classification
    fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC)')
    plt.legend(loc="lower right")
    plt.show()

"""# **Feature Importance Plot**"""

def plot_feature_importance(model, X_test, y_test):
    """Plots the feature importance plot for Random Forest."""
    if isinstance(model, RandomForestClassifier):
        result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)
        importances = result.importances_mean
        forest_importances = pd.Series(importances, index=X.columns)
        fig, ax = plt.subplots()
        forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
        ax.set_title("Feature importances using permutation on full model")
        ax.set_ylabel("Mean accuracy decrease")
        fig.tight_layout()
        plt.show()
plot_feature_importance(rf, X_test, y_test)

"""# **Precision-Recall Curve**"""

def plot_precision_recall_curve(y_true, y_pred):
    """Plots the precision-recall curve."""
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)
    pr_auc = auc(recall, precision)
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='darkorange', lw=2, label='PR curve (area = %0.2f)' % pr_auc)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc="lower right")
    plt.show()
plot_precision_recall_curve(y_test_binary, y_pred)

"""# **RMSE Score**"""

def calculate_and_print_rmse(y_true, y_pred):
    """Calculates and prints the RMSE."""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    print(f"RMSE: {rmse}")
calculate_and_print_rmse(y_test_binary, y_pred)

print(classification_report(y_test,y_pred))
print(classification_report(y_test,y_pred1))

"""# **Evaluation Metrics for Classification**"""

from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import numpy as np

report = classification_report(y_test, y_pred, output_dict=True) # or y_pred1

# Get the actual class labels from the report dictionary
categories = list(report.keys())[:-3]  # Exclude 'accuracy', 'macro avg', 'weighted avg'

metrics = ['precision', 'recall', 'f1-score']

# Reshape data to have metrics as rows and categories as columns
data = [[report[category][metric] for category in categories] for metric in metrics]


X = np.arange(len(categories))
width = 0.2  # Width of the bars

fig, ax = plt.subplots()

# Create bars for each metric separately
for i, metric in enumerate(metrics):
    rects = ax.bar(X + i * width, data[i], width, label=metric)  # Label with metric name


ax.set_ylabel('Scores')
ax.set_title('Classification Report Metrics')
ax.set_xticks(X + width)  # Adjust x-tick positions for better alignment
ax.set_xticklabels(categories)  # Use actual class labels for x-axis ticks
ax.legend()

fig.tight_layout()
plt.show()
plt.show()